---
title: "<Romanello>-<Domenic>-Homework-03"
author: "Dom-Romanello"
date: "3/21/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

library(curl)
library(tidyverse)
library(readr)
library(ggplot2)
library(gridExtra)
library(manipulate)
library(lmodel2)

```

Question 1!!

Write a simple R function you call Z.prop.test(), that can perform one- or two-sample Z-tests for proportion data, using the following guidelines.

Your function should take the following arguments: p1 and n1 (no default) representing the estimated proportion and sample size (e.g., based on your sample data); p2 and n2 (both defaulting to NULL) that contain a second sample’s proportion and sample size data in the event of a two-sample test; p0 (no default) as the expected value for the population proportion; and alternative (default “two.sided”) and conf.level (default 0.95), to be used in the same way as in the function t.test().

When conducting a two-sample test, it should be p1 that is tested as being smaller or larger than p2 when alternative=“less” or alternative=“greater”, respectively, the same as in the use of x and y in the function t.test().

The function should perform a one-sample Z-test using p1, n1, and p0 if either p2 or n2 (or both) is NULL.

The function should contain a check for the rules of thumb we have talked about (n×π>5 and n×(1−π)>5) to ensure the validity of assuming the normal distribution in both the one- and two-sample settings. If this is violated, the function should still complete, but it should also print an appropriate warning message.

The function should return a list containing the following elements: Z (the test statistic), P (the appropriate p value), and CI (the two-sided CI with respect to “conf.level” around p1 in the case of a one-sample test and around p2-p1 in the case of a two-sample test). For all test alternatives (“two.sided”, “greater”, “less”), calculate symmetric CIs based on quantiles of the normal distribution rather than worrying about calculating single-limit confidence bounds.

```{r}

Z.Prop.Test <- function(p1, p2=NULL, n1, n2=NULL, p0, alternative="less", conf.level= .95) {
if(is.null(p2))
p1 <- mean(x)
n1 <- length(x)
p0 <- 
z <- (p1 - p0)/sqrt(p0 * (1 - p0) / n1)
p <- pnorm(z, lower.tail = TRUE)
lower.ci <- p1 - qnorm(conf.level) sqrt(p1 (1 - p1)/n1)
upper.ci <- p1 + qnorm(conf.level) sqrt(p1 (1 - p1)/n1)
if((n1*p1)>5 & (n1*(1-p1)) > 5){
print("Warning: Normal Distribution Assumption Violation")
}
outcome <- list(z, p, lower.ci, upper.ci)
names(outcome) <- c("z", "p", "lower.ci", "upper.ci")
}
outcome
}


```

```{r}
Z.Prop.Test(p1=23,n1=41)

v1 <- c(0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 
1, 1, 0, 1, 0, 1, 1)

  
if(is.null(p2)){


p1 <- mean(v1)
n1 <- length(v1)
p0 <- .8
z <- (p1 - p0)/sqrt(p0 * (1 - p0) / n1)
p <- pnorm(z, lower.tail = TRUE)
lower.ci <- p1 - qnorm(conf.level) sqrt(p1 (1 - p1)/n1)
upper.ci <- p1 + qnorm(conf.level) sqrt(p1 (1 - p1)/n1)


}}

z.prop.test <- function(p1, p2 = NULL, n1, n2 = NULL, p0, alternative = "less", conf.level = 0.95){
# Coding for one-sample Z-test:
if(is.null(p2)){
p1 <- mean(v1)
n1 <- length(v1)
p0 <- .8
z <- (p1 - p0)/sqrt(p0 * (1 - p0) / n1)
p <- pnorm(z, lower.tail = TRUE)
lower.ci <- p1 - qnorm(conf.level) sqrt(p1 (1 - p1)/n1)
upper.ci <- p1 + qnorm(conf.level) sqrt(p1 (1 - p1)/n1)
if((n1*p1)>5 && (n1*(1-p1)) > 5){
message("Validation: Be careful! The assumption of normal distribution is violated!")
}
else{
message("Validation: Data are normally distributed!")
}
outcome <- list(z, p, lower.ci, upper.ci)
names(outcome) <- c("z", "p", "lower.ci", "upper.ci")
}
outcome
}


# use Tony's examples to test and make sure get same values. 
```













Question 2!!

The comparative primate dataset we have used from Kamilar and Cooper has in it a large number of variables related to life history and body size. For this exercise, the end aim is to fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from species’ brain size (Brain_Size_Species_Mean) measured in grams. Do the following for both longevity~brain size and log(longevity)~log(brain size).

```{r}
f <- curl("https://raw.githubusercontent.com/difiore/ADA-2019/master/KamilarAndCooperData.csv")
d <- read.csv(f, header = TRUE, stringsAsFactors = FALSE)
d <- as_tibble(d)
attach(d)
head(d)
```

Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot (HINT: use the function geom_text()).

```{r}

plot(data = d, MaxLongevity_m ~ Brain_Size_Species_Mean)
g <- ggplot(data = d, aes(x = Brain_Size_Species_Mean, y = MaxLongevity_m))
g <- g + geom_point()
g <- g + geom_smooth(method = "lm", formula = y ~ x)
g <- g + geom_text(x=200, y=800, label="y=1.218x + 248.952", color="blue")
g

plot(data = d, log(MaxLongevity_m) ~ log(Brain_Size_Species_Mean))
g <- ggplot(data = d, aes(x = log(Brain_Size_Species_Mean), y = log(MaxLongevity_m)))
g <- g + geom_point()
g <- g + geom_smooth(method = "lm", formula = y ~ x)
g <- g + geom_text(x= 1.4, y=6.5, label="y=.23415x + 4.87895", color="blue")
g

```

Identify and interpret the point estimate of the slope (β1), as well as the outcome of the test associated with the hypotheses H0: β1=0; HA: β1≠0. Also, find a 90% CI for the slope (β1) parameter.

Answers for Longevity~Brain:

β1 = 1.218

5% = 1.035571

95% = 1.40041

Brain size is a highly significant predictor of longevity, as brain size increases longevity does too, positive correlation. 

Answers for Log(Longevity)~Log(Brain):

β1 = .23415

5% = .2046396

95% = .2636595

Log brain size is a highly significant predictor of log longevity, as log brain size increases log longevity does too, positive correlation. 



```{r}

m <- lm(data = d, MaxLongevity_m ~ Brain_Size_Species_Mean)
summary(m)

alpha <- 0.1

m$lmCI <- confint(m, level = 1 - alpha)  
m$lmCI

logm <- lm(data = d, log(MaxLongevity_m) ~ log(Brain_Size_Species_Mean))
summary(logm)

alpha <- 0.1

logm$lmCI <- confint(logm, level = 1 - alpha)  
logm$lmCI

```

Using your model, add lines for the 90% confidence and prediction interval bands on the plot, and add a legend to differentiate between the lines.

```{r}

ci <- predict(m, newdata = data.frame(Longevity = d$MaxLongevity_m), interval = "confidence", level = 0.90)  
head(ci)

pi <- predict(m, newdata = data.frame(Longevity = d$MaxLongevity_m), interval = "predict", level = 0.90)  
head(pi)

m <- lm(data = d, MaxLongevity_m ~ Brain_Size_Species_Mean)
Longevity <- predict(m, newdata = data.frame(BrainSize = d$Brain_Size_Species_Mean))

df <- data.frame(cbind(d$Brain_Size_Species_Mean, d$MaxLongevity_m, Longevity))
names(df) <- c("x", "y", "yhat")
head(df)

dff <- cbind(df, ci)
names(dff) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr")
head(dff)

dfff <- cbind(dff, pi)
names(dfff) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", "PIupr")
head(dfff)

g <- ggplot(data = dff, aes(x = x, y = y))
g <- g + geom_point(alpha = 0.5)
g <- g + geom_line(aes(x = x, y = CIfit, colour = "black"))
g <- g + geom_line(aes(x = x, y = CIlwr, colour = "blue"))
g <- g + geom_line(aes(x = x, y = CIupr, colour = "blue"))
g <- g + geom_line(data = dfff, aes(x = x, y = PIlwr, colour = "red"))
g <- g + geom_line(data = dfff, aes(x = x, y = PIupr, colour = "red"))
g

```

Log

```{r}


ci <- predict(m, newdata = data.frame(Longevity = log(d$MaxLongevity_m)), interval = "confidence", level = 0.90)  
head(ci)

pi <- predict(m, newdata = data.frame(Longevity = log(d$MaxLongevity_m)), interval = "predict", level = 0.90)  
head(pi)

m <- lm(data = d, log(MaxLongevity_m) ~ log(Brain_Size_Species_Mean))
Longevity <- predict(m, newdata = data.frame(BrainSize = log(d$Brain_Size_Species_Mean)))

df <- data.frame(cbind(log(d$Brain_Size_Species_Mean), log(d$MaxLongevity_m), Longevity))
names(df) <- c("x", "y", "yhat")
head(df)

dff <- cbind(df, ci)
names(dff) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr")
head(dff)

dfff <- cbind(dff, pi)
names(dfff) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", "PIupr")
head(dfff)

g <- ggplot(data = dff, aes(x = x, y = y))
g <- g + geom_point(alpha = 0.5)
g <- g + geom_line(aes(x = x, y = CIfit, colour = "black"))
g <- g + geom_line(aes(x = x, y = CIlwr, colour = "blue"))
g <- g + geom_line(aes(x = x, y = CIupr, colour = "blue"))
g <- g + geom_line(data = dfff, aes(x = x, y = PIlwr, colour = "red"))
g <- g + geom_line(data = dfff, aes(x = x, y = PIupr, colour = "red"))
g

```
Produce a point estimate and associated 90% prediction interval for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?

```{r}

ci <- predict(m, newdata = data.frame(Brain_Size_Species_Mean = 800), interval = "confidence", level = 0.90)  
ci

```


Looking at your two models, which do you think is better? Why?


