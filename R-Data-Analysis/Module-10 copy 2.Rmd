---
title: "Module10"
author: "Dom-Romanello"
date: "2/13/2019"
output: html_document
---

```{r setup, include= FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

library(sciplot)

x <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 25, 50, 100, 200, 1000)
gm1 <- function(x) {
    prod(x)^(1/length(x))
}
gm1(x)

gm2 <- function(x) {
    exp(mean(log(x)))
}
gm2(x)


ss2 <- function(x) {
    sum(x^2) - length(x) * mean(x)^2
}
ss2(x)

ss3 <- function(x) {
    sum(x^2) - (sum(x))^2/length(x)
}
ss3(x)

pop_v <- function(x) {
    sum((x - mean(x))^2)/(length(x))
}
pop_v(x)

sample_v <- function(x) {
    sum((x - mean(x))^2)/(length(x) - 1)
}
sample_v(x)

plot(c(0, 100), c(0, 15), type = "n", xlab = "Sample size", ylab = "Variance")

for (n in seq(5, 100, 5)) # samples of 5, 10, 15...
{
    for (i in 1:50) # 50 replicates
    {
        x <- rnorm(n, mean = 10, sd = 2)
        points(n, var(x))
    }
}

pop_sd <- function(x) {
    sqrt(pop_v(x))
}
pop_sd(x)

sample_sd <- function(x) {
    sqrt(sample_v(x))
}
sample_sd(x)

se1 <- function(x) {
    sqrt(sample_v(x)/length(x))
}
se1(x)

se2 <- function(x) {
    sqrt(var(x)/length(x))
}
se2(x)

se3 <- function(x) {
    sd(x)/sqrt(length(x))
}
se3(x)

library(sciplot)
se(x)

set.seed(1)
x <- rnorm(10000, 0, 1)
hist(x, main = "")

x <- seq(from = -4, to = 4, by = 0.01)
plot(x, dnorm(x), cex = 0.4, type = "l", xlab = "# SD", ylab = "Density", xlim = c(-4, 
    4))


plot(x, pnorm(x), cex = 0.4, type = "l", xlab = "# SD", ylab = "Cumulative Probability", 
    xlim = c(-4, 4))

x <- seq(from = 0, to = 1, by = 0.001)
plot(x, qnorm(x), cex = 0.4, type = "l", xlab = "Quantile", ylab = "# SD", xlim = c(-0.05, 
    1.05))

plot(qnorm(x), x, cex = 0.4, type = "l", xlab = "# SD", ylab = "Quantile", ylim = c(-0.05, 
    1.05))

x <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)
m <- mean(x)
n <- length(x)
v <- var(x)
s <- sd(x)
e <- sqrt(v/n)
upper <- mean(x) + qnorm(0.975, mean = 0, sd = 1) * se(x)
lower <- mean(x) + qnorm(0.025, mean = 0, sd = 1) * se(x)  # or lower <- mean(x) - qnorm(0.975)*se(x)
ci <- c(lower, upper)
ci

upper <- m + qnorm(0.975, mean = 0, sd = 1) * e
lower <- m + qnorm(0.025, mean = 0, sd = 1) * e  # or lower <- m - qnorm(0.975)*e
ci <- c(lower, upper)
ci

normalCI = function(x, CIlevel = 0.95) {
    upper = m + qnorm(1 - (1 - CIlevel)/2) * sqrt(var(x)/length(x))
    lower = m + qnorm((1 - CIlevel)/2) * sqrt(var(x)/length(x))
    ci <- c(lower, upper)
    return(ci)
}
normalCI(x, 0.95)  # call the function

combination <- NULL  # sets up a dummy variable to hold our 10000 simulations
n <- 15
for (i in 1:10000) {
    combination[i] <- mean(sample(x, n, replace = TRUE))
}
hist(combination, xlab = "Sum of Rolls", main = "")
abline(v = mean(combination))
abline(v = mean(x), col = "red")
ci <- normalCI(x, 0.95)  # call the function
abline(v = ci[1], col = "red")  # calculated lower ci bound based on se
abline(v = ci[2], col = "red")  # calculated upper ci bound based on se
quantile(combination)

quantile(combination, c(0.025, 0.975))

abline(v = quantile(combination, 0.025), col = "blue")  # lower ci bound inferred by simulation
abline(v = quantile(combination, 0.975), col = "blue")  # upper ci bound inferred by simulation



```
Challenge 1

```{r}

x <- c(1,2,3,4,5,6,7,8,9,10,25,50,100,200,1000)

library(psych)

geometric.mean( x, na.rm=TRUE)

gm1 <- function(x) {
    prod(x)^(1/length(x))
}
gm1(x)

```